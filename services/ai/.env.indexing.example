# Indexing Pipeline Configuration Example
# Copy this file to .env.indexing and adjust the paths for your environment

# Content Configuration
# Path to the directory containing your blog content (with 'blog' and 'engineering' subdirectories)
INDEXING_CONTENT_CONTENT_ROOT=/path/to/your/project/services/ai/data/content

# Database Configuration  
# Path to the LanceDB vector database directory
INDEXING_DATABASE_DB_PATH=/path/to/your/project/services/ai/data/lancedb

# Processing Configuration
# Path to the cache directory for embeddings and processed content
INDEXING_PROCESSING_CACHE_DIR=/path/to/your/project/services/ai/data/cache

# Optional: Override default settings
# Uncomment and modify these as needed

# Logging level (DEBUG, INFO, WARNING, ERROR)
# INDEXING_LOG_LEVEL=INFO

# Environment (development, production)
# INDEXING_ENVIRONMENT=development

# Embedding model configuration
# INDEXING_EMBEDDING_MODEL_NAME=all-MiniLM-L6-v2
# INDEXING_EMBEDDING_BATCH_SIZE=16
# INDEXING_EMBEDDING_DEVICE=cpu

# Text chunking configuration
# INDEXING_CHUNKING_CHUNK_SIZE=1000
# INDEXING_CHUNKING_CHUNK_OVERLAP=200
# INDEXING_CHUNKING_MIN_CHUNK_SIZE=100

# Database configuration
# INDEXING_DATABASE_TABLE_NAME=blog_content
# INDEXING_DATABASE_CREATE_IVF_INDEX=true
# INDEXING_DATABASE_IVF_PARTITIONS=256

# Processing configuration
# INDEXING_PROCESSING_MAX_MEMORY_USAGE_MB=512
# INDEXING_PROCESSING_MAX_WORKERS=2
# INDEXING_PROCESSING_ENABLE_EMBEDDING_CACHE=true
